# è®¾è®¡æ–‡æ¡£ï¼šçˆ¬è™«æ¶æ„é‡æ„ - ç»Ÿä¸€ç»§æ‰¿ä½“ç³»

**æ–‡æ¡£ç¼–å·**: DESIGN-2026-02-06-001  
**åˆ›å»ºæ—¥æœŸ**: 2026-02-06  
**ä½œè€…**: Chang (æ¶æ„å¸ˆ)  
**çŠ¶æ€**: ğŸ“ è‰æ¡ˆ

---

## 1. èƒŒæ™¯ä¸é—®é¢˜

### 1.1 å½“å‰æ¶æ„é—®é¢˜

åœ¨å®ç°åŠ¨æ€æ–°é—»é¡µé¢çˆ¬è™«ï¼ˆ`DynamicNewsCrawler`ï¼‰åï¼Œå‘ç°å½“å‰æ¶æ„å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å½“å‰ç±»å…³ç³»å›¾                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Parser å±‚:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚  BBSParser   â”‚ â—„â”€â”€â”€ DynamicPageParser (ç»§æ‰¿) âœ…              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                 â”‚
â”‚  Crawler å±‚:                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚  BBSSpider   â”‚ â—„â”€â”€â”€ DiscuzSpider (ç»§æ‰¿)                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â—„â”€â”€â”€ PhpBBSpider (ç»§æ‰¿)                       â”‚
â”‚                   â—„â”€â”€â”€ VBulletinSpider (ç»§æ‰¿)                   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚ DynamicNewsCrawler â”‚  âŒ ç‹¬ç«‹å­˜åœ¨ï¼Œæœªçº³å…¥ç»§æ‰¿ä½“ç³»            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚                                                                 â”‚
â”‚  Factory å±‚:                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚ SpiderFactory  â”‚ â”€â”€â”€ åªç®¡ç† BBSSpider åŠå…¶å­ç±»               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     âŒ ä¸ç®¡ç† DynamicNewsCrawler            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| é—®é¢˜ | æè¿° | å½±å“ |
|------|------|------|
| **ç»§æ‰¿å…³ç³»ä¸ä¸€è‡´** | `DynamicPageParser` ç»§æ‰¿ `BBSParser`ï¼Œä½† `DynamicNewsCrawler` ä¸ç»§æ‰¿ `BBSSpider` | ä»£ç ç»“æ„æ··ä¹± |
| **å·¥å‚æ¨¡å¼ä¸å®Œæ•´** | `SpiderFactory` åªç®¡ç† BBS çˆ¬è™« | æ— æ³•ç»Ÿä¸€åˆ›å»ºçˆ¬è™« |
| **ä»£ç é‡å¤** | `DynamicNewsCrawler` æœ‰ç‹¬ç«‹çš„ `fetch_page`ã€`stats`ã€`session` | ç»´æŠ¤æˆæœ¬é«˜ |
| **æ¦‚å¿µæ··æ·†** | BBS å’Œ Dynamic æ˜¯å¹¶åˆ—è¿˜æ˜¯ç»§æ‰¿ï¼Ÿ | éš¾ä»¥æ‰©å±• |

### 1.2 é‡å¤ä»£ç åˆ†æ

| åŠŸèƒ½ | BBSSpider | DynamicNewsCrawler | é‡å¤ï¼Ÿ |
|------|-----------|-------------------|--------|
| HTTP Session ç®¡ç† | âœ… `self.session` | âœ… `self.session` | ğŸ”´ é‡å¤ |
| é¡µé¢è·å– | âœ… `fetch_page()` | âœ… `fetch_page()` | ğŸ”´ é‡å¤ |
| ç»Ÿè®¡ä¿¡æ¯ | âœ… `self.stats` | âœ… `self.stats` | ğŸ”´ é‡å¤ |
| å¼‚æ­¥ä¸Šä¸‹æ–‡ | âœ… `__aenter__/__aexit__` | âœ… `__aenter__/__aexit__` | ğŸ”´ é‡å¤ |
| è¯·æ±‚å¤´ç®¡ç† | âœ… `get_headers()` | âœ… `get_headers()` | ğŸ”´ é‡å¤ |
| é…ç½®ç®¡ç† | âœ… `self.config` | âœ… `self.config` | ğŸ”´ é‡å¤ |

---

## 2. è®¾è®¡ç›®æ ‡

1. **ç»Ÿä¸€ç»§æ‰¿ä½“ç³»** - æ‰€æœ‰çˆ¬è™«ç±»å…±äº«åŸºç±»
2. **æ¶ˆé™¤ä»£ç é‡å¤** - å…¬å…±åŠŸèƒ½æŠ½å–åˆ°åŸºç±»
3. **å·¥å‚æ¨¡å¼å®Œæ•´** - `SpiderFactory` ç®¡ç†æ‰€æœ‰çˆ¬è™«ç±»å‹
4. **æ˜“äºæ‰©å±•** - æ–°å¢çˆ¬è™«ç±»å‹åªéœ€ç»§æ‰¿å’Œæ³¨å†Œ
5. **å‘åå…¼å®¹** - ç°æœ‰ API ä¿æŒä¸å˜

---

## 3. æ¶æ„è®¾è®¡

### 3.1 æ¨èæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ¨èç±»å…³ç³»å›¾                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Parser å±‚ (ä¿æŒä¸å˜):                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚    BBSParser     â”‚  â—„â”€â”€â”€ DynamicPageParser (ç»§æ‰¿)            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                                 â”‚
â”‚  Crawler å±‚ (é‡æ„):                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚   BaseSpider     â”‚  â—„â”€â”€ æ–°å¢ï¼æŠ½å–å…¬å…±åŠŸèƒ½                   â”‚
â”‚  â”‚  - config        â”‚      (HTTPè¯·æ±‚ã€ç»Ÿè®¡ã€sessionç®¡ç†)        â”‚
â”‚  â”‚  - session       â”‚                                           â”‚
â”‚  â”‚  - stats         â”‚                                           â”‚
â”‚  â”‚  - fetch_page()  â”‚                                           â”‚
â”‚  â”‚  - get_headers() â”‚                                           â”‚
â”‚  â”‚  - __aenter__()  â”‚                                           â”‚
â”‚  â”‚  - __aexit__()   â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚           â”‚                                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚    â–¼                         â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  BBSSpider   â”‚    â”‚ DynamicNewsCrawler â”‚                     â”‚
â”‚  â”‚  (è®ºå›çˆ¬è™«)   â”‚    â”‚ (åŠ¨æ€é¡µé¢çˆ¬è™«)      â”‚                     â”‚
â”‚  â”‚  - parser    â”‚    â”‚ - parser           â”‚                     â”‚
â”‚  â”‚  - crawl_*   â”‚    â”‚ - crawl_*          â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚         â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚  â–¼          â–¼          â–¼                                        â”‚
â”‚ Discuz   PhpBB    VBulletin                                     â”‚
â”‚                                                                 â”‚
â”‚  Factory å±‚ (æ‰©å±•):                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚ SpiderFactory  â”‚ â”€â”€â”€ ç»Ÿä¸€ç®¡ç†æ‰€æœ‰çˆ¬è™«ç±»å‹                    â”‚
â”‚  â”‚  _registry:    â”‚                                             â”‚
â”‚  â”‚  - discuz      â”‚ â†’ DiscuzSpider                              â”‚
â”‚  â”‚  - phpbb       â”‚ â†’ PhpBBSpider                               â”‚
â”‚  â”‚  - vbulletin   â”‚ â†’ VBulletinSpider                           â”‚
â”‚  â”‚  - generic     â”‚ â†’ BBSSpider                                 â”‚
â”‚  â”‚  - dynamic     â”‚ â†’ DynamicNewsCrawler  ğŸ†•                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ç±»è®¾è®¡

#### 3.2.1 BaseSpider (æ–°å¢)

```python
class BaseSpider(ABC):
    """
    çˆ¬è™«åŸºç±»
    
    æ‰€æœ‰çˆ¬è™«çš„å…¬å…±åŸºç±»ï¼Œæä¾›ï¼š
    - HTTP Session ç®¡ç†
    - é¡µé¢è·å–
    - ç»Ÿè®¡ä¿¡æ¯
    - å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†
    """
    
    def __init__(self, config: Config):
        self.config = config
        self.session: Optional[aiohttp.ClientSession] = None
        self.stats = {
            'pages_fetched': 0,
            'requests_failed': 0,
        }
    
    async def __aenter__(self) -> 'BaseSpider':
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.init()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.close()
    
    async def init(self):
        """åˆå§‹åŒ–çˆ¬è™«ï¼ˆåˆ›å»ºsessionç­‰ï¼‰"""
        timeout = aiohttp.ClientTimeout(total=self.config.crawler.request_timeout)
        self.session = aiohttp.ClientSession(timeout=timeout)
    
    async def close(self):
        """å…³é—­çˆ¬è™«ï¼ˆæ¸…ç†èµ„æºï¼‰"""
        if self.session:
            await self.session.close()
    
    def get_headers(self) -> Dict[str, str]:
        """è·å–è¯·æ±‚å¤´"""
        return {
            "User-Agent": self.config.crawler.user_agent or UserAgent().random,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        }
    
    async def fetch_page(self, url: str, headers: Optional[Dict] = None) -> Optional[str]:
        """
        è·å–é¡µé¢å†…å®¹
        
        Args:
            url: é¡µé¢URL
            headers: å¯é€‰çš„é¢å¤–è¯·æ±‚å¤´
        
        Returns:
            HTMLå†…å®¹ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            request_headers = self.get_headers()
            if headers:
                request_headers.update(headers)
            
            async with self.session.get(url, headers=request_headers) as response:
                if response.status == 200:
                    self.stats['pages_fetched'] += 1
                    return await response.text()
                else:
                    logger.warning(f"HTTP {response.status}: {url}")
                    return None
        except Exception as e:
            self.stats['requests_failed'] += 1
            logger.error(f"è·å–é¡µé¢å¤±è´¥ {url}: {e}")
            return None
    
    @abstractmethod
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass
```

#### 3.2.2 BBSSpider (ä¿®æ”¹)

```python
class BBSSpider(BaseSpider):
    """
    BBSè®ºå›çˆ¬è™«
    
    ç»§æ‰¿ BaseSpiderï¼Œæ·»åŠ è®ºå›ç‰¹æœ‰åŠŸèƒ½ï¼š
    - å¸–å­åˆ—è¡¨è§£æ
    - å¸–å­è¯¦æƒ…çˆ¬å–
    - å›¾ç‰‡ä¸‹è½½
    """
    
    def __init__(self, config: Config):
        super().__init__(config)
        self.parser = BBSParser()
        self.downloader = None
        self.deduplicator = None
        self.storage = None
        
        # BBSç‰¹æœ‰ç»Ÿè®¡
        self.stats.update({
            'threads_crawled': 0,
            'images_found': 0,
            'images_downloaded': 0,
            'images_failed': 0,
            'duplicates_skipped': 0,
        })
    
    async def init(self):
        """åˆå§‹åŒ–BBSçˆ¬è™«"""
        await super().init()  # è°ƒç”¨åŸºç±»åˆå§‹åŒ–
        # BBSç‰¹æœ‰åˆå§‹åŒ–
        self.downloader = ImageDownloader(...)
        self.deduplicator = ImageDeduplicator(...)
        self.storage = Storage(...)
    
    async def close(self):
        """å…³é—­BBSçˆ¬è™«"""
        # BBSç‰¹æœ‰æ¸…ç†
        if self.downloader:
            await self.downloader.close()
        await super().close()  # è°ƒç”¨åŸºç±»å…³é—­
    
    # ... å…¶ä»–BBSç‰¹æœ‰æ–¹æ³•
```

#### 3.2.3 DynamicNewsCrawler (ä¿®æ”¹)

```python
class DynamicNewsCrawler(BaseSpider):
    """
    åŠ¨æ€æ–°é—»é¡µé¢çˆ¬è™«
    
    ç»§æ‰¿ BaseSpiderï¼Œæ·»åŠ åŠ¨æ€é¡µé¢ç‰¹æœ‰åŠŸèƒ½ï¼š
    - Ajaxåˆ†é¡µå¤„ç†
    - æ–‡ç« è¯¦æƒ…çˆ¬å–
    - å›¾ç‰‡æå–
    """
    
    def __init__(self, config: Config):
        super().__init__(config)
        self.parser = DynamicPageParser(config)
        
        # åŠ¨æ€é¡µé¢ç‰¹æœ‰ç»Ÿè®¡
        self.stats.update({
            'articles_found': 0,
            'articles_crawled': 0,
            'articles_failed': 0,
            'images_downloaded': 0,
            'images_failed': 0,
        })
    
    async def fetch_page(self, url: str, headers: Optional[Dict] = None, is_ajax: bool = False) -> Optional[str]:
        """
        é‡å†™ fetch_pageï¼Œæ”¯æŒ Ajax è¯·æ±‚
        """
        request_headers = headers or {}
        if is_ajax:
            request_headers["X-Requested-With"] = "XMLHttpRequest"
        return await super().fetch_page(url, request_headers)
    
    # ... å…¶ä»–åŠ¨æ€é¡µé¢ç‰¹æœ‰æ–¹æ³•
```

#### 3.2.4 SpiderFactory (æ‰©å±•)

```python
class SpiderFactory:
    """
    çˆ¬è™«å·¥å‚ç±»
    
    ç»Ÿä¸€ç®¡ç†æ‰€æœ‰çˆ¬è™«ç±»å‹çš„åˆ›å»º
    """
    
    _registry: Dict[str, Type[BaseSpider]] = {
        # BBSç±»å‹
        'discuz': DiscuzSpider,
        'phpbb': PhpBBSpider,
        'vbulletin': VBulletinSpider,
        'generic': BBSSpider,
        # åŠ¨æ€é¡µé¢ç±»å‹
        'dynamic': DynamicNewsCrawler,  # ğŸ†• æ–°å¢
    }
    
    @classmethod
    def create(cls, 
               config: Optional[Config] = None, 
               url: Optional[str] = None, 
               preset: Optional[str] = None,
               spider_type: Optional[str] = None  # ğŸ†• æ–°å¢å‚æ•°
    ) -> BaseSpider:
        """
        åˆ›å»ºçˆ¬è™«å®ä¾‹
        
        Args:
            config: é…ç½®å¯¹è±¡
            url: è®ºå›URLï¼ˆç”¨äºè‡ªåŠ¨æ£€æµ‹ï¼‰
            preset: è®ºå›ç±»å‹é¢„è®¾
            spider_type: çˆ¬è™«ç±»å‹ (bbs/dynamic)
        
        Returns:
            çˆ¬è™«å®ä¾‹
        """
        # ç¡®å®šçˆ¬è™«ç±»å‹
        if spider_type == 'dynamic':
            return DynamicNewsCrawler(config or Config())
        
        # åŸæœ‰BBSé€»è¾‘...
```

### 3.3 CLI æ›´æ–°

```bash
# ç°æœ‰å‘½ä»¤ï¼ˆä¿æŒä¸å˜ï¼‰
spider.py crawl-url "https://bbs.com/thread/123" --auto-detect
spider.py crawl-urls --config xindong
spider.py crawl-board "https://bbs.com/forum/1" --config xindong
spider.py crawl-boards --config xindong

# åŠ¨æ€é¡µé¢å‘½ä»¤ï¼ˆå·²å®ç°ï¼‰
spider.py crawl-news "https://sxd.xd.com/" --download-images --max-pages 5
```

---

## 4. å®ç°è®¡åˆ’

### 4.1 é˜¶æ®µåˆ’åˆ†

| é˜¶æ®µ | å†…å®¹ | é¢„è®¡æ—¶é—´ | é£é™© |
|------|------|---------|------|
| **é˜¶æ®µ1** | åˆ›å»º `BaseSpider` åŸºç±» | 30åˆ†é’Ÿ | ä½ |
| **é˜¶æ®µ2** | ä¿®æ”¹ `BBSSpider` ç»§æ‰¿ `BaseSpider` | 30åˆ†é’Ÿ | ä¸­ |
| **é˜¶æ®µ3** | ä¿®æ”¹ `DynamicNewsCrawler` ç»§æ‰¿ `BaseSpider` | 30åˆ†é’Ÿ | ä¸­ |
| **é˜¶æ®µ4** | æ‰©å±• `SpiderFactory` | 15åˆ†é’Ÿ | ä½ |
| **é˜¶æ®µ5** | æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯• | 30åˆ†é’Ÿ | ä½ |

### 4.2 æ–‡ä»¶å˜æ›´

| æ–‡ä»¶ | å˜æ›´ç±»å‹ | å†…å®¹ |
|------|---------|------|
| `spider.py` | ä¿®æ”¹ | æ·»åŠ  `BaseSpider`ï¼Œä¿®æ”¹ `BBSSpider` |
| `core/dynamic_crawler.py` | ä¿®æ”¹ | ç»§æ‰¿ `BaseSpider`ï¼Œåˆ é™¤é‡å¤ä»£ç  |
| `run_spider.sh` | ä¿®æ”¹ | æ·»åŠ  `crawl-news` ç¤ºä¾‹ |
| `ARCHITECTURE.md` | ä¿®æ”¹ | æ›´æ–°æ¶æ„å›¾ |
| `README.md` | ä¿®æ”¹ | æ·»åŠ åŠ¨æ€é¡µé¢çˆ¬è™«æ–‡æ¡£ |

### 4.3 å‘åå…¼å®¹

| API | å…¼å®¹æ€§ | è¯´æ˜ |
|-----|--------|------|
| `SpiderFactory.create()` | âœ… å®Œå…¨å…¼å®¹ | ç°æœ‰å‚æ•°ä¿æŒä¸å˜ |
| `BBSSpider` | âœ… å®Œå…¨å…¼å®¹ | å…¬å…±æ¥å£ä¸å˜ |
| `DynamicNewsCrawler` | âœ… å®Œå…¨å…¼å®¹ | å…¬å…±æ¥å£ä¸å˜ |
| CLI å‘½ä»¤ | âœ… å®Œå…¨å…¼å®¹ | ç°æœ‰å‘½ä»¤ä¿æŒä¸å˜ |

---

## 5. é£é™©è¯„ä¼°

| é£é™© | å¯èƒ½æ€§ | å½±å“ | ç¼“è§£æªæ–½ |
|------|--------|------|---------|
| ç»§æ‰¿é“¾è¿‡æ·± | ä½ | ä¸­ | åªæœ‰2å±‚ç»§æ‰¿ |
| æ¥å£ä¸å…¼å®¹ | ä¸­ | é«˜ | å……åˆ†æµ‹è¯•ï¼Œä¿æŒå…¬å…±æ¥å£ |
| æ€§èƒ½ä¸‹é™ | ä½ | ä½ | åŸºç±»æ–¹æ³•ç®€å•ï¼Œæ— æ€§èƒ½å½±å“ |

---

## 6. æµ‹è¯•è®¡åˆ’

### 6.1 å•å…ƒæµ‹è¯•

```python
# æµ‹è¯• BaseSpider
def test_base_spider_init():
    spider = ConcreteSpider(config)
    assert spider.session is None
    
async def test_base_spider_fetch_page():
    async with ConcreteSpider(config) as spider:
        html = await spider.fetch_page("https://example.com")
        assert html is not None
```

### 6.2 é›†æˆæµ‹è¯•

```bash
# æµ‹è¯• BBS çˆ¬è™«
python spider.py crawl-url "https://bbs.xd.com/..." --config xindong

# æµ‹è¯•åŠ¨æ€é¡µé¢çˆ¬è™«
python spider.py crawl-news "https://sxd.xd.com/" --download-images --max-pages 2
```

---

## 7. å®¡æ‰¹

| è§’è‰² | å§“å | æ„è§ | æ—¥æœŸ |
|------|------|------|------|
| æ¶æ„å¸ˆ | Chang | å¾…å®¡æ‰¹ | - |
| å¼€å‘è€… | - | å¾…å®¡æ‰¹ | - |

---

## 8. é™„å½•

### 8.1 å‚è€ƒèµ„æ–™

- [Python ABC æ¨¡å—æ–‡æ¡£](https://docs.python.org/3/library/abc.html)
- [è®¾è®¡æ¨¡å¼ï¼šæ¨¡æ¿æ–¹æ³•æ¨¡å¼](https://refactoring.guru/design-patterns/template-method)

### 8.2 ç›¸å…³è®¾è®¡æ–‡æ¡£

- `docs/designs/2026-02-05-dynamic-news-page-crawler.md` - åŠ¨æ€æ–°é—»é¡µé¢çˆ¬è™«è®¾è®¡
- `docs/designs/2026-02-04-implement-subcommand-mode.md` - å­å‘½ä»¤æ¨¡å¼å®ç°

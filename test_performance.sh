#!/bin/bash
# æ€§èƒ½æµ‹è¯•è„šæœ¬ - æµ‹è¯• crawl-news çš„å¼‚æ­¥é˜Ÿåˆ—æ€§èƒ½

echo "============================================================"
echo "ğŸš€ crawl-news æ€§èƒ½æµ‹è¯•"
echo "============================================================"
echo ""

URL="https://sxd.xd.com/"
MAX_PAGES=3

echo "æµ‹è¯•URL: $URL"
echo "æœ€å¤§é¡µæ•°: $MAX_PAGES"
echo ""

# æµ‹è¯•1: ä¸²è¡Œæ¨¡å¼ï¼ˆä¸ä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼‰
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ”¹ æµ‹è¯•1: ä¸²è¡Œæ¨¡å¼ï¼ˆä¸ä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼‰"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
time python3 spider.py crawl-news "$URL" \
    --max-pages $MAX_PAGES \
    --no-async-queue \
    --no-resume \
    --max-workers 1 \
    2>&1 | grep -E "(å‘ç°|çˆ¬å–|è€—æ—¶|é€Ÿåº¦|ç»Ÿè®¡|articles_found|articles_crawled|pages_fetched)" | head -20

echo ""
echo "ç­‰å¾…5ç§’..."
sleep 5
echo ""

# æµ‹è¯•2: å¹¶è¡Œæ¨¡å¼ï¼ˆä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼Œ5å¹¶å‘ï¼‰
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ”¹ æµ‹è¯•2: å¹¶è¡Œæ¨¡å¼ï¼ˆä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼Œ5å¹¶å‘ï¼‰"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
time python3 spider.py crawl-news "$URL" \
    --max-pages $MAX_PAGES \
    --no-resume \
    --max-workers 5 \
    2>&1 | grep -E "(å‘ç°|çˆ¬å–|è€—æ—¶|é€Ÿåº¦|ç»Ÿè®¡|articles_found|articles_crawled|pages_fetched|é˜Ÿåˆ—)" | head -20

echo ""
echo "ç­‰å¾…5ç§’..."
sleep 5
echo ""

# æµ‹è¯•3: å¹¶è¡Œæ¨¡å¼ï¼ˆä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼Œ10å¹¶å‘ï¼‰
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ”¹ æµ‹è¯•3: å¹¶è¡Œæ¨¡å¼ï¼ˆä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼Œ10å¹¶å‘ï¼‰"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
time python3 spider.py crawl-news "$URL" \
    --max-pages $MAX_PAGES \
    --no-resume \
    --max-workers 10 \
    2>&1 | grep -E "(å‘ç°|çˆ¬å–|è€—æ—¶|é€Ÿåº¦|ç»Ÿè®¡|articles_found|articles_crawled|pages_fetched|é˜Ÿåˆ—)" | head -20

echo ""
echo "============================================================"
echo "âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ"
echo "============================================================"

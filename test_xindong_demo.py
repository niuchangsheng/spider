"""
å¿ƒåŠ¨è®ºå›çˆ¬è™« - æ¼”ç¤ºç‰ˆæœ¬ï¼ˆä»…ä½¿ç”¨Pythonæ ‡å‡†åº“ï¼‰
ç”¨äºæµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®
"""
import urllib.request
import urllib.parse
from html.parser import HTMLParser
import re
import sys

# å¿ƒåŠ¨è®ºå›é…ç½®
XINDONG_BASE_URL = "https://bbs.xd.com"
EXAMPLE_THREAD = "https://bbs.xd.com/forum.php?mod=viewthread&tid=3479145&extra=page%3D1"


class ImageExtractor(HTMLParser):
    """ç®€å•çš„HTMLå›¾ç‰‡æå–å™¨"""
    
    def __init__(self):
        super().__init__()
        self.images = []
        self.current_tag = None
    
    def handle_starttag(self, tag, attrs):
        if tag == 'img':
            attrs_dict = dict(attrs)
            # æå–å›¾ç‰‡URL
            src = attrs_dict.get('src') or attrs_dict.get('file') or attrs_dict.get('data-src')
            if src and not src.startswith('static/'):
                self.images.append(src)
        
        # æ£€æŸ¥é™„ä»¶é“¾æ¥
        if tag == 'a':
            attrs_dict = dict(attrs)
            href = attrs_dict.get('href', '')
            if 'mod=attachment' in href:
                self.images.append(href)


def fetch_page(url):
    """è·å–é¡µé¢å†…å®¹"""
    print(f"\næ­£åœ¨è·å–é¡µé¢: {url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=30) as response:
            html = response.read().decode('utf-8', errors='ignore')
            print(f"âœ“ é¡µé¢è·å–æˆåŠŸï¼Œå¤§å°: {len(html)} å­—èŠ‚")
            return html
    except Exception as e:
        print(f"âœ— é¡µé¢è·å–å¤±è´¥: {e}")
        return None


def extract_images(html):
    """æå–å›¾ç‰‡é“¾æ¥"""
    parser = ImageExtractor()
    try:
        parser.feed(html)
    except:
        pass
    
    images = []
    for img in parser.images:
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if img.startswith('forum.php') or img.startswith('/forum.php'):
            img = f"{XINDONG_BASE_URL}/{img.lstrip('/')}"
        
        # æ·»åŠ å‚æ•°è·å–åŸå›¾
        if 'mod=attachment' in img and 'nothumb' not in img:
            img += '&nothumb=yes'
        
        # è¿‡æ»¤æ— æ•ˆé“¾æ¥
        if img.startswith('http') or img.startswith('//'):
            if img.startswith('//'):
                img = 'https:' + img
            images.append(img)
    
    return list(set(images))  # å»é‡


def extract_thread_info(html):
    """æå–å¸–å­ä¿¡æ¯"""
    info = {}
    
    # æå–æ ‡é¢˜ï¼ˆç®€å•æ­£åˆ™åŒ¹é…ï¼‰
    title_match = re.search(r'<title>(.*?)</title>', html)
    if title_match:
        info['title'] = title_match.group(1).strip()
    
    # æå–ä½œè€…
    author_match = re.search(r'class="author"[^>]*>(.*?)</a>', html)
    if author_match:
        info['author'] = re.sub(r'<[^>]+>', '', author_match.group(1)).strip()
    
    # æå–æŸ¥çœ‹æ•°
    view_match = re.search(r'æŸ¥çœ‹:\s*(\d+)', html)
    if view_match:
        info['views'] = view_match.group(1)
    
    # æå–å›å¤æ•°
    reply_match = re.search(r'å›å¤:\s*(\d+)', html)
    if reply_match:
        info['replies'] = reply_match.group(1)
    
    return info


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("å¿ƒåŠ¨è®ºå›çˆ¬è™« - æ¼”ç¤ºç‰ˆæœ¬")
    print("=" * 70)
    print("\nğŸ“Œ ç›®æ ‡å¸–å­:")
    print(f"   {EXAMPLE_THREAD}")
    print("\nâš ï¸  è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç‰ˆæœ¬ï¼Œä»…ä½¿ç”¨Pythonæ ‡å‡†åº“")
    print("   å®Œæ•´åŠŸèƒ½è¯·å®‰è£…ä¾èµ–åä½¿ç”¨ crawl_xindong.py")
    
    # è·å–é¡µé¢
    html = fetch_page(EXAMPLE_THREAD)
    if not html:
        print("\nâŒ æ— æ³•è·å–é¡µé¢ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return
    
    # æå–å¸–å­ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ğŸ“‹ å¸–å­ä¿¡æ¯:")
    print("=" * 70)
    
    info = extract_thread_info(html)
    for key, value in info.items():
        print(f"   {key}: {value}")
    
    # æå–å›¾ç‰‡
    print("\n" + "=" * 70)
    print("ğŸ–¼ï¸  å›¾ç‰‡é“¾æ¥:")
    print("=" * 70)
    
    images = extract_images(html)
    
    if images:
        print(f"\nå‘ç° {len(images)} å¼ å›¾ç‰‡:\n")
        for i, img_url in enumerate(images, 1):
            print(f"{i:2d}. {img_url}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é™„ä»¶
            if 'mod=attachment' in img_url:
                print(f"    â””â”€ [é™„ä»¶] éœ€è¦ä¸‹è½½æ‰èƒ½æŸ¥çœ‹")
            
        print("\n" + "=" * 70)
        print("âœ… å›¾ç‰‡æå–å®Œæˆï¼")
        print("=" * 70)
        
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. å®‰è£…å®Œæ•´ä¾èµ–: pip3 install -r requirements.txt")
        print("   2. è¿è¡Œå®Œæ•´ç‰ˆæœ¬: python3 crawl_xindong.py")
        print("   3. å›¾ç‰‡å°†è‡ªåŠ¨ä¸‹è½½åˆ° downloads/ ç›®å½•")
    else:
        print("\nâŒ æœªå‘ç°å›¾ç‰‡é“¾æ¥")
        print("   å¯èƒ½åŸå› :")
        print("   - é¡µé¢ç»“æ„å·²å˜åŒ–")
        print("   - éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹")
        print("   - ç½‘ç»œé—®é¢˜")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
